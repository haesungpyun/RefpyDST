{
  "train_fn": "mw21_5p_train_v1.json",
  "test_fn": "mw24_20p_dev.json",
"retriever_dir": "retriever/pretrained_index/context_bs/",

  "retriever_args":  {
    "state_transformation": "ref_aware",
    "input_type": "context"
  },
  "prompt_format": "python-prompt",
  "codex_engine":"../models/Meta-Llama-3-70B-Instruct-GPTQ",
  "quantization":"GPTQ",
  "num_examples": 10,
  "decoding_pool": "all_train_set",
  "lm_decoding_config": {
    "method": "greedy",
    "beam_size": 4
  }
}
